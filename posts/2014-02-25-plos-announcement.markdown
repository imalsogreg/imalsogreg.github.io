---
title: PLOS's scary-awesome new data-sharing mandate
---

## Here is what's happening at PLOS

This might make you squirm with discomfort. But you know it's right... deep down. Or if not, I hope I can convince you.

<blockquote>
  <p>We are now revising our data-sharing policy for all PLOS journals: <em>authors must make all data publicly available, without restriction, immediately upon publication of the article</em>. Beginning March 3rd, 2014, all authors who submit to a PLOS journal will be asked to provide a Data Availability Statement, describing where and how others can access each dataset that underlies the findings.</p>
  <footer>
    <cite>
      <a href="http://blogs.plos.org/everyone/2014/02/24/plos-new-data-policy-public-access-data/">
	PLOS' New Data Policy: Public Access to Data</a> Liz Silva, Feb 24, 2014
    </cite>
  </footer>
</blockquote>

<p>And an update to their policy page:</p>

<blockquote>
  <p>PLOS defines the &quot;minimal dataset&quot; to consist of the dataset used to reach the conclusions drawn in the manuscript with related metadata and methods, and any additional data required to replicate the reported study findings in their entirety. Core descriptive data, methods, and study results should be included within the main paper, regardless of data deposition. PLOS does not accept references to &quot;data not shown&quot;.</p>
  <footer>
    <cite>
      <a href="http://www.plos.org/data-access-for-the-open-access-literature-ploss-data-policy/">Data Access for the Open Access Literature: PLOS' Data Policy</a> 
      Theo Bloom
    </cite>
  </footer>
</blockquote>

Are you thinking, &quot;I spent years collecting that data, and some modeler is going to mine it for all the interesting results? How can I get a high-impact factor paper and a job with that type of scoop target on my back?&quot; 

Or, &quot;God what if someone discovers a bug in my code, it turns out my finding isn't real - will I be kicked out of science?&quot;  

Hold that thought, because I want to tell you why this scary policy is actually not a threat to your career.  On the contrary, if you have felt like academia brought you in as an idealist, and slowly crushed you into a career pragmatist, there may be something interesting for you here.

## Data-sharing will bring career pragmatism into line with science idealism

That's the main point. First, let's agree on what this policy is about on the surface:

 * Making sure that authors aren't cheating their data
 * Helping us catch bugs in each other's code (like [sign-flip-induced Nature paper retractions](http://boscoh.com/protein/a-sign-a-flipped-structure-and-a-scientific-flameout-of-epic-proportions.html))
 * Enabling super-cheap pilot experiments to help pick fruitful paths, avoid false starts and precious time wastage
 * Not having to kill so many monkeys (simple data sharing)
 * Making an awesome playground for high school science and data-analysis classes
 * etc

*But*, back to those valid concerns raised above! &quot;Yes those things are great and I'm all for them. What I don't like is the fact that I don't get to benefit from the hard work I put into collecting my data and writing my code - it's now *everyone's* data and code. <strong>How can I compete for jobs when other people don't have to spend time collecting data?</strong>&quot;

What I want to say is, not only can you rest easy with those concerns, but that the *reason* you can rest easy is the <strong>best</strong> part of this whole crazy policy change. Why?

## The obsoleted reward system

What gets you hired, today? 

*Easy. High-impact papers, fundability (they're the same thing).* 

What makes a high-impact paper? 

*A complete publishable unit built on an exciting finding.* 

When all data and code are shared, can individuals and individual labs expect to be first-to-publish on more than one or two papers from their single hard-won data set or codebase? 

*HAH! (I mean, I doubt it. Probably not)*

The gut reaction to that is &quot;Oh no I can't meet the standard if I give away my prime assets!&quot;. But my prediction is, our current system for judging scientists just doesn't work in the new open-science context. <em>The standards will adjust to the type of productivity we **can** achieve under the new system</em>. *And that new type of productivity is awesome - it's the thing we wish science were all about - synergy.*

## New productivity standards in the open-science universe

A few predictions for how we'll rank scientists, when the idea of the <span style="border:1px;border-color:black;border-style:dashed;">publishable unit</span> becomes quaint:

 * <strong>Data production is valued for what it is, independent of the analysis done on it.</strong> <br/>Rather than being rewarded for the number of novel discoveries we **make**, we will be rewarded for the number of discoveries we **facilitate**. Think of it this way - you are valued not for the number of findings you can lay claim to, but for the number of findings that you allowed the community to uncover (the latter being the much larger number).

 * <strong>Data analysis is valued independent of the difficulty of generating the data.</strong> <br/>Collecting great data and doing great analysis are very different skills. Put one person in charge of both, and it becomes very hard to carry out the experiments for Figs 3 - 5 objectively, when Figs 1 - 2 show something *sooo* promising. When we reward *production* and *analysis* separately, this tension just evaporates. There are two papers, and it should always have been that way to avoid conflicts of interest.

 * <strong>Mandatory code sharing rewards pro-social coding, discourages wheel-reinvention and bug-smuggling</strong> <br/>Most scientists code out of necessity, not out of some kind of love of the craft. Being completely honest, the result is that a lot of our code is dangerously [smelly](http://www.codinghorror.com/blog/2006/05/code-smells.html). The coming system that values our code contributions will reward coders that make use of and contribute to shared code bases. There is no way around it - open, community coding will hoist us up by the bootstraps into the realm of software engineering, unit-testing, and exploration of safer languages and practices.

<br/>

So, what do these predictions have in common? I don't know if it's a happy coincidence, or foresight on the part of PLOS and other leaders in the open science movement, but there is one clear thread here. **Open-science mandates could change the reward structure in a way that brings pro-social behavior into better alignment with individual career ambition** and *that* is the killer app. 

Think about science as it's practiced now. What's the relationship between the career ambitions of the average scientist and the greater good of the science community? Do they always line up? I'm talking about the daily pressures that get to all of us. That one behavioral assay that didn't work out like the other three, and our PI is telling us, &quot;Let's keep the story simple&quot;. The vague sense, &quot;That matlab code handed down from the previous postdoc - it gives me a nice effect on my data, but I'm not really sure how it works&quot;... 

&quot;*I believe in not cutting corners, in doing solid science. I just have to secure my career first with a high-impact paper.*&quot;

The story is different in the pharmaceutical industry, where being wrong about basic science could cost you millions of dollars in dead-end clinical trials. The incentives in Pharma, at the preclinical stage, are not to get a glamorous publication, but to be right. And when the Pharma companies started noticing that some academic science results are failing as a foundation for new work, they re-ran the published experiments and found that [89% of landmark papers in cancer biology fail to replicate](http://www.nature.com/nature/journal/v483/n7391/full/483531a.html). Money that should be going toward curing cancer, is instead funding those desperate pangs for academic job security.

Despite what we say about the self-correcting nature of science, these cancer findings never faced replication scrutiny until industry came in. Amazing. Science is more broken than most of us thought. But after being an insider for a while, *being face-to-face with the tension between objectivity and your career*, the number begins to feel less surprising.

Not everyone agrees with me that the tension between career success and scientific progress is the cause of our replication crisis. But for those who do entertain the idea, *there is a lot to be hopeful for in these PLOS reforms*. In addition to the list of obvious gains that open-data and open-code bring, there is this much more powerful (though I admit, speculative) idea - **PLOS's system is the first one that brings your individual ambition into alignment with the greater good**. In the absence of a path for rewarding the status quo, what's left to reward is *synergy*. That's what it all comes down to. The old system rewards hiding and owning. The new system rewards synergy. And that gives me a lot of hope for the future of our community - that we might safely get to be idealists again. Thanks for reading!
